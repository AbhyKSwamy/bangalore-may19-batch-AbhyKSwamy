{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"6. Plant_Seed_CNN Project1.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"YaBr-erZncce","colab":{}},"source":["from google.colab import drive"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gF5meo6Pnd-y","outputId":"b9e35953-bd2e-4890-b3f9-638dbcb05f7a","executionInfo":{"status":"ok","timestamp":1578211942094,"user_tz":-330,"elapsed":28536,"user":{"displayName":"abhyuday kumara swamy","photoUrl":"","userId":"08253165596985941487"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["drive.mount('/content/drive/') # Mounting the Drive onto colab"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ivJgjcGSnf-C","colab":{}},"source":["import os\n","os.chdir('/content/drive/My Drive/')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zrEWFArOqFXs","colab":{}},"source":["os.chdir('/content/drive/My Drive/train')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PfhxmZSxqNeg","outputId":"78cfda33-a2a4-4cf0-a51a-d8cab2b4a5f4","executionInfo":{"status":"ok","timestamp":1578211951762,"user_tz":-330,"elapsed":872,"user":{"displayName":"abhyuday kumara swamy","photoUrl":"","userId":"08253165596985941487"}},"colab":{"base_uri":"https://localhost:8080/","height":218}},"source":["os.listdir() # Eyeballing the class labels."],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Maize',\n"," 'Common Chickweed',\n"," 'Small-flowered Cranesbill',\n"," 'Fat Hen',\n"," 'Sugar beet',\n"," 'Shepherds Purse',\n"," 'Cleavers',\n"," 'Common wheat',\n"," 'Loose Silky-bent',\n"," 'Scentless Mayweed',\n"," 'Black-grass',\n"," 'Charlock']"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8BYcVPZUqOMi","outputId":"376b4fb4-ff65-4c53-920c-a46f744d4921","executionInfo":{"status":"ok","timestamp":1578213178176,"user_tz":-330,"elapsed":230893,"user":{"displayName":"abhyuday kumara swamy","photoUrl":"","userId":"08253165596985941487"}},"colab":{"base_uri":"https://localhost:8080/","height":218}},"source":["# Extracting training data from the directories and storing the features and thier class labels.\n","# I have trained multiple models in  this notebook and it should be noted that I have changed the dimensions of the images for different models. \n","# The model which I've built has inputs the shape of (128X128X3), while the ResNets50 and VGG19 (from the keras API) uses (224X224X3) as input shape.\n","# The data has class imbalance, as I got to know from the dataset information. \n","# The total number of images from the training data is also less.\n","# Also, the project questions asks us to evaluate accuraices for the training and validation data. Here I have NOT evaluated on the testset.\n","\n","\n","\n","x_train = []\n","y_train = []\n","import cv2\n","for i in os.listdir():\n","    print(i)\n","    if (os.path.isdir(i)):\n","            for j in os.listdir(i):\n","                try:\n","                    dummy = cv2.imread('/content/drive/My Drive/train/' + i + \"/\" + j)\n","                    dummy = cv2.resize(dummy,(224,224))\n","                    x_train.append(dummy)\n","                    y_train.append(i)\n","                except Exception as e:\n","                    print(e)\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Maize\n","Common Chickweed\n","Small-flowered Cranesbill\n","Fat Hen\n","Sugar beet\n","Shepherds Purse\n","Cleavers\n","Common wheat\n","Loose Silky-bent\n","Scentless Mayweed\n","Black-grass\n","Charlock\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KVTWzHBLvLkR","outputId":"35291a90-e127-4959-ee4e-29f29f0c831f","executionInfo":{"status":"ok","timestamp":1578213242560,"user_tz":-330,"elapsed":1234,"user":{"displayName":"abhyuday kumara swamy","photoUrl":"","userId":"08253165596985941487"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x_train[0].shape"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(224, 224, 3)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jX9jD090uIxX","colab":{}},"source":["import pandas as pd\n","dum = pd.get_dummies(y_train) # converting the class labels to categorical variables"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2LniWcretNjt","colab":{}},"source":["encoded_labels = dum\n","y_train = dum"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yW1MRzNzscJD","colab":{}},"source":["import numpy as np\n","y_train = np.array(y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"i_4kF4C9qV73","colab":{}},"source":["x_train = np.array(x_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"69ZkfU51usBT","outputId":"b16b2dc8-491a-4947-e1e6-fc7435488651","executionInfo":{"status":"ok","timestamp":1578213251791,"user_tz":-330,"elapsed":767,"user":{"displayName":"abhyuday kumara swamy","photoUrl":"","userId":"08253165596985941487"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x_train[0].shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(224, 224, 3)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VzBQIPBAuQwN","outputId":"c7b36007-9549-431f-e0ea-70ae44de5aa2","executionInfo":{"status":"ok","timestamp":1578213255036,"user_tz":-330,"elapsed":1629,"user":{"displayName":"abhyuday kumara swamy","photoUrl":"","userId":"08253165596985941487"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["from sklearn.model_selection import train_test_split\n","x_train2, x_val, y_train2, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=2) # Splitting data into training and validation sets.\n","print (len(x_train2))\n","print (len(x_val))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["3808\n","952\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zOXrhr_huSPR","outputId":"2e63d63d-f026-42f9-cc8b-1fe13928b4ec","executionInfo":{"status":"ok","timestamp":1578213259648,"user_tz":-330,"elapsed":994,"user":{"displayName":"abhyuday kumara swamy","photoUrl":"","userId":"08253165596985941487"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x_train2[0].shape"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(224, 224, 3)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dMocdt9JuVOJ","colab":{}},"source":["x_train2 = x_train2.reshape(x_train2.shape[0],224,224,3) # Reshaping dataset so that it can be fed to the model."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"k1KiJod-uWkR","colab":{}},"source":["x_val = x_val.reshape(x_val.shape[0],224,224,3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RGjH72OuCfeY","colab":{}},"source":["x_train2 = x_train2/255. # Normalizing the features.\n","\n","x_val = x_val/255."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TyWC85VZvS5_","outputId":"ac59f0b4-551c-465a-a1f1-369ec0d02f6d","executionInfo":{"status":"ok","timestamp":1578213299671,"user_tz":-330,"elapsed":1021,"user":{"displayName":"abhyuday kumara swamy","photoUrl":"","userId":"08253165596985941487"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["print (x_train2.shape)\n","print (x_val.shape)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["(3808, 224, 224, 3)\n","(952, 224, 224, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DKgWlwHSvUc2","outputId":"20e2a7af-8ba6-43b9-ca28-0192e5e30120","executionInfo":{"status":"ok","timestamp":1578213302662,"user_tz":-330,"elapsed":1406,"user":{"displayName":"abhyuday kumara swamy","photoUrl":"","userId":"08253165596985941487"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["print(y_train2.shape)\n","print(y_val.shape)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["(3808, 12)\n","(952, 12)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rxP3Ck6jo5WA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":79},"outputId":"ebdbc21b-b619-4593-f3df-8c91c9868c94","executionInfo":{"status":"ok","timestamp":1578213335004,"user_tz":-330,"elapsed":25015,"user":{"displayName":"abhyuday kumara swamy","photoUrl":"","userId":"08253165596985941487"}}},"source":["# I've employed Data Augmentation to make the training more robust.\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","datagen=ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True,zca_whitening=False,zoom_range=0.2,\n","    rotation_range=50,  \n","    width_shift_range=0.1,  \n","    height_shift_range=0.1,  \n","    horizontal_flip=True, \n","    vertical_flip=True)\n","\n","datagen.fit(x_train2)\n","datagen.fit(x_val)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"EaouYL1fo5jd","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FBbScZrJjC5h","colab_type":"code","colab":{}},"source":["tf.keras.backend.clear_session()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I9Ig7zOZo5vG","colab_type":"code","colab":{}},"source":["# Initializing the seqential model -\n","model = tf.keras.models.Sequential()\n","\n","\n","# Adding three convolutional layers with increasing depth , ReLU activation function applied to all Conv layers.\n","model.add(tf.keras.layers.Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(128,128,3),name='conv_1'))\n","model.add(tf.keras.layers.Conv2D(64,kernel_size=(3,3),activation='relu',name='conv_2'))\n","\n","# I've commented out the dropout layer, it was not added to the model.\n","#model.add(tf.keras.layers.Dropout(0.3,name='drop_1'))\n","\n","# Adding a Pooling layer to reduce inputs to relevant dimensions-\n","model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),name='max_1'))\n","\n","\n","# Adding more depth to the CNN model \n","model.add(tf.keras.layers.Conv2D(128,kernel_size=(3,3),activation='relu',name='conv_5'))\n","model.add(tf.keras.layers.Conv2D(128,kernel_size=(3,3),activation='relu',name='conv_6'))\n","\n","\n","# Adding another pooling layer-\n","model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),name='max_3'))\n","\n","\n","# Adding more convolutional layers of increasing depth -\n","model.add(tf.keras.layers.Conv2D(256,kernel_size=(3,3),activation='relu',name='conv_7'))\n","model.add(tf.keras.layers.Conv2D(256,kernel_size=(3,3),activation='relu',name='conv_8'))\n","\n","# Adding the third pooling layer -\n","model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),name='max_4'))\n","\n","# Adding the final convolutional layer -\n","model.add(tf.keras.layers.Conv2D(512,kernel_size=(3,3),activation='relu',name='conv_9'))\n","\n","# Adding the final pooling layer - \n","model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),name='max_5'))\n","\n","\n","# Flattening the Convolved/Pooled layers to 1D-\n","model.add(tf.keras.layers.Flatten())\n","\n","# Adding Fully Connected layers with relU activation functions -\n","model.add(tf.keras.layers.Dense(150,activation='relu',name='dense_0'))\n","\n","# Adding a BatchNormlayer\n","model.add(tf.keras.layers.BatchNormalization())\n","\n","# Dropout not added to the model as done for the convolutional layers above.\n","#model.add(tf.keras.layers.Dropout(0.4,name='drop_2'))\n","\n","# Adding the next FC layers-\n","model.add(tf.keras.layers.Dense(100,activation='relu',name='dense_1'))\n","model.add(tf.keras.layers.Dense(50,activation='relu',name='dense_2'))\n","model.add(tf.keras.layers.Dense(20,activation='relu',name='dense_3'))\n","\n","\n","# Adding the output layer with number of classes as output and the activation function as softmax-\n","model.add(tf.keras.layers.Dense(12,activation='softmax',name='dense_4'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XIflo_vVo5yv","colab_type":"code","colab":{}},"source":["# Compiling the model with adam optimizer optimizing the categorical crossentropy loss function.\n","\n","model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-jdy6j3no51m","colab_type":"code","outputId":"78dda12a-7a9a-4a73-d121-eab0b94aa2e0","executionInfo":{"status":"ok","timestamp":1578160312235,"user_tz":-330,"elapsed":58540,"user":{"displayName":"abhyuday kumara swamy","photoUrl":"","userId":"08253165596985941487"}},"colab":{"base_uri":"https://localhost:8080/","height":386}},"source":["# Training and validating the model -\n","model.fit(x_train2, y_train2, batch_size=128,epochs=10,validation_data=(x_val,y_val))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 3808 samples, validate on 952 samples\n","Epoch 1/10\n","3808/3808 [==============================] - 6s 2ms/sample - loss: 0.0386 - acc: 0.9903 - val_loss: 0.8674 - val_acc: 0.7447\n","Epoch 2/10\n","3808/3808 [==============================] - 6s 2ms/sample - loss: 0.0205 - acc: 0.9963 - val_loss: 0.9480 - val_acc: 0.7090\n","Epoch 3/10\n","3808/3808 [==============================] - 6s 2ms/sample - loss: 0.0131 - acc: 0.9971 - val_loss: 0.7653 - val_acc: 0.7668\n","Epoch 4/10\n","3808/3808 [==============================] - 6s 2ms/sample - loss: 0.0095 - acc: 0.9992 - val_loss: 0.7100 - val_acc: 0.8120\n","Epoch 5/10\n","3808/3808 [==============================] - 6s 2ms/sample - loss: 0.0046 - acc: 0.9997 - val_loss: 0.8323 - val_acc: 0.7731\n","Epoch 6/10\n","3808/3808 [==============================] - 6s 2ms/sample - loss: 0.0035 - acc: 1.0000 - val_loss: 0.7064 - val_acc: 0.8193\n","Epoch 7/10\n","3808/3808 [==============================] - 6s 2ms/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.8192 - val_acc: 0.7994\n","Epoch 8/10\n","3808/3808 [==============================] - 6s 2ms/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.7874 - val_acc: 0.8193\n","Epoch 9/10\n","3808/3808 [==============================] - 6s 2ms/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.7021 - val_acc: 0.8361\n","Epoch 10/10\n","3808/3808 [==============================] - 6s 2ms/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.7150 - val_acc: 0.8403\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f84403389e8>"]},"metadata":{"tags":[]},"execution_count":152}]},{"cell_type":"code","metadata":{"id":"7Yrz7GYVo5sS","colab_type":"code","colab":{}},"source":["# OBSERVATIONS AND MODEL TUNING -\n","\n","\n","# It has to be noted that first, the dataset is very small especially for the multivariate classes. The class labels are also imbalanced.\n","# I got very poor accurices with running the data as it was, therefore I employed data augmentation and noticed Immediate improvement.\n","# I also fitted the whole data, not just in batches as the data was sparce, this also helped imprive accuracies. The accuracies were still low (around 25%).\n","# I built a model mimicking VGG16, but the model perfomed even more poorly ( due to vanishing gradient). We have to keep in mind that the VGG researchers added untrained layers \n","# inbetween trained layers (mimicking the yet to be develped skip connections of the Resnet). As I did not do this, my model performed poorly.\n","# Thus I started to progressively stack more convolution layers based upon my increasing accuracy rate with each cycle. ( I had about 50% accuracy at this stage)\n","# What really aided my inrease in accuracy to about 85% as seen above, was to either add Dropout layers or BatchNorm, not both together.\n","# Out of both, though BatchNorm overfitted more, this acctucally helped to increase the validation accuracy.\n","# The main problem overall was that the model wasnt able to converge fast even with ADAM. The loss occillated quite a bit with every runtime.\n","# Due to time constraints, I am unable to babysit the model further, but in my opinion getting an accuracy above 95 % would be tough with the above architecture.\n","# Thus, one can appreciate the need for a large dataset with balanced classes and the leap forward that was achived with ResNets "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dzdAgjKgo5pM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XJ6lNgPUTBHM","colab_type":"code","colab":{}},"source":["#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PCldTNj0TBKp","colab_type":"code","colab":{}},"source":["# The models below are beyond the purview of the project and I am running and tuning the models just to see how I can play with them. \n","# At this stage I am still continuing to tune the models. \n","# Interestingly the Resnet model perfomed more poorly when I used the pruned model, freezing the first five layers and adding the top layers when compared \n","# to the whole model [include_top=True]. It seems that the weights learned during for the imagent challenge is quite valuable."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IrqAXHf2TBEM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"osZEyBMgo5mj","colab_type":"code","colab":{}},"source":["import keras"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6CrrjsBoFwxZ","colab":{}},"source":["from keras import applications\n","from keras.models import Sequential, Model \n","from keras.layers import Dropout, Flatten, Dense\n","from keras import backend as k \n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BIB_XcqbFw0F","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"c4b9b16b-97de-4780-9e5d-5794a04d279f","executionInfo":{"status":"ok","timestamp":1578221235894,"user_tz":-330,"elapsed":7259,"user":{"displayName":"abhyuday kumara swamy","photoUrl":"","userId":"08253165596985941487"}}},"source":["model = applications.ResNet50(weights = None, include_top=False, input_shape = (224, 224, 3))"],"execution_count":62,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n","  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JSYa2I84Fw2v","outputId":"538e6c05-e9c6-4124-9781-224780b3542f","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1578221241053,"user_tz":-330,"elapsed":1139,"user":{"displayName":"abhyuday kumara swamy","photoUrl":"","userId":"08253165596985941487"}}},"source":["# Freezing the first 25 layers.\n","for layer in model.layers[:25]:\n","    layer.trainable = False\n","\n","#Adding custom Layers \n","x = model.output\n","x = Flatten()(x)\n","x = Dense(1024, activation=\"relu\")(x)\n","x = Dropout(0.5)(x)\n","x = Dense(64, activation=\"relu\")(x)\n","x = Dense(32, activation=\"relu\")(x)\n","predictions = Dense(12, activation=\"softmax\")(x)\n","\n","# creating the final model \n","model_final = Model(input = model.input, output = predictions)\n","\n","\n","\n","# compile the model \n","model_final.compile(loss = \"categorical_crossentropy\", optimizer =  keras.optimizers.SGD(lr=0.001, nesterov=True), metrics=[\"accuracy\"])\n"],"execution_count":63,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"k50K_p9xFw8l","outputId":"c3880196-e578-41c6-ef2e-0a7cae56b3cc","colab":{"base_uri":"https://localhost:8080/","height":605},"executionInfo":{"status":"ok","timestamp":1578221738563,"user_tz":-330,"elapsed":493694,"user":{"displayName":"abhyuday kumara swamy","photoUrl":"","userId":"08253165596985941487"}}},"source":["# Save the model \n","checkpoint = ModelCheckpoint(\"ResNet_best.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n","early = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto')\n","\n","epochs=20\n","# Train the model \n","model_final.fit(x_train2, y_train2, epochs = epochs, validation_data=(x_val, y_val), callbacks = [checkpoint, early])"],"execution_count":64,"outputs":[{"output_type":"stream","text":["Train on 3808 samples, validate on 952 samples\n","Epoch 1/20\n","3808/3808 [==============================] - 53s 14ms/step - loss: 2.6623 - acc: 0.0964 - val_loss: 2.4655 - val_acc: 0.1092\n","\n","Epoch 00001: val_acc improved from -inf to 0.10924, saving model to ResNet_best.h5\n","Epoch 2/20\n","3808/3808 [==============================] - 30s 8ms/step - loss: 2.5209 - acc: 0.1053 - val_loss: 2.4617 - val_acc: 0.1229\n","\n","Epoch 00002: val_acc improved from 0.10924 to 0.12290, saving model to ResNet_best.h5\n","Epoch 3/20\n","3808/3808 [==============================] - 30s 8ms/step - loss: 2.5051 - acc: 0.1006 - val_loss: 2.4568 - val_acc: 0.1303\n","\n","Epoch 00003: val_acc improved from 0.12290 to 0.13025, saving model to ResNet_best.h5\n","Epoch 4/20\n","3808/3808 [==============================] - 30s 8ms/step - loss: 2.4671 - acc: 0.1119 - val_loss: 2.4468 - val_acc: 0.1124\n","\n","Epoch 00004: val_acc did not improve from 0.13025\n","Epoch 5/20\n","3808/3808 [==============================] - 29s 8ms/step - loss: 2.4488 - acc: 0.1266 - val_loss: 2.4413 - val_acc: 0.1134\n","\n","Epoch 00005: val_acc did not improve from 0.13025\n","Epoch 6/20\n","3808/3808 [==============================] - 29s 8ms/step - loss: 2.4445 - acc: 0.1197 - val_loss: 2.4467 - val_acc: 0.1134\n","\n","Epoch 00006: val_acc did not improve from 0.13025\n","Epoch 7/20\n","3808/3808 [==============================] - 29s 8ms/step - loss: 2.4349 - acc: 0.1200 - val_loss: 2.4424 - val_acc: 0.1197\n","\n","Epoch 00007: val_acc did not improve from 0.13025\n","Epoch 8/20\n","3808/3808 [==============================] - 29s 8ms/step - loss: 2.4309 - acc: 0.1295 - val_loss: 2.4411 - val_acc: 0.1124\n","\n","Epoch 00008: val_acc did not improve from 0.13025\n","Epoch 00008: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f9ace67d240>"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"code","metadata":{"id":"WNlx38dcWlvN","colab_type":"code","colab":{}},"source":["# As seen by the accuray above, freezing first 25 layers also perfomes poorly."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wDtz1gnnWuUa","colab_type":"code","colab":{}},"source":["#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aTJnVhtNWvJe","colab_type":"code","colab":{}},"source":["# Applying the VGG19  model ------ "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JJOvuIiYINkg","colab":{}},"source":["model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (224, 224, 3))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q17moLS8-zF1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"4c0ed214-d5f5-498b-d8d8-88711819d1c5","executionInfo":{"status":"ok","timestamp":1578216344449,"user_tz":-330,"elapsed":1082,"user":{"displayName":"abhyuday kumara swamy","photoUrl":"","userId":"08253165596985941487"}}},"source":["# Freeze the layers which you don't want to train. In this we are freezing the first 5 layers.\n","for layer in model.layers[:5]:\n","    layer.trainable = False\n","\n","#Adding custom Layers \n","x = model.output\n","x = Flatten()(x)\n","x = Dense(1024, activation=\"relu\")(x)\n","x = Dropout(0.5)(x)\n","x = Dense(64, activation=\"relu\")(x)\n","x = Dense(32, activation=\"relu\")(x)\n","predictions = Dense(12, activation=\"softmax\")(x)\n","\n","# creating the final model \n","model_final = Model(input = model.input, output = predictions)\n","\n","#optim=(tf.keras.optimizers.SGD(learning_rate=0.01, nesterov=True))\n","\n","# compile the model \n","model_final.compile(loss = \"categorical_crossentropy\", optimizer = keras.optimizers.SGD(lr=0.001, nesterov=True), metrics=[\"accuracy\"])\n"],"execution_count":50,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"0qgyXG4I-zZI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"a0f100a1-e338-4b92-dedf-002e175366d0","executionInfo":{"status":"ok","timestamp":1578217525508,"user_tz":-330,"elapsed":435533,"user":{"displayName":"abhyuday kumara swamy","photoUrl":"","userId":"08253165596985941487"}}},"source":["# Save the model \n","checkpoint = ModelCheckpoint(\"vgg16_best.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n","early = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto')\n","\n","epochs=20\n","# Train the model \n","model_final.fit(x_train2, y_train2, epochs = epochs, validation_data=(x_val, y_val), callbacks = [checkpoint, early])"],"execution_count":52,"outputs":[{"output_type":"stream","text":["Train on 3808 samples, validate on 952 samples\n","Epoch 1/20\n","3808/3808 [==============================] - 30s 8ms/step - loss: 0.1869 - acc: 0.9362 - val_loss: 0.3344 - val_acc: 0.8845\n","\n","Epoch 00001: val_acc improved from -inf to 0.88445, saving model to vgg16_best.h5\n","Epoch 2/20\n","3808/3808 [==============================] - 30s 8ms/step - loss: 0.1929 - acc: 0.9357 - val_loss: 0.3832 - val_acc: 0.8624\n","\n","Epoch 00002: val_acc did not improve from 0.88445\n","Epoch 3/20\n","3808/3808 [==============================] - 30s 8ms/step - loss: 0.1429 - acc: 0.9493 - val_loss: 0.3113 - val_acc: 0.8897\n","\n","Epoch 00003: val_acc improved from 0.88445 to 0.88971, saving model to vgg16_best.h5\n","Epoch 4/20\n","3808/3808 [==============================] - 30s 8ms/step - loss: 0.1507 - acc: 0.9477 - val_loss: 0.2842 - val_acc: 0.8908\n","\n","Epoch 00004: val_acc improved from 0.88971 to 0.89076, saving model to vgg16_best.h5\n","Epoch 5/20\n","3808/3808 [==============================] - 30s 8ms/step - loss: 0.1403 - acc: 0.9543 - val_loss: 0.3058 - val_acc: 0.8929\n","\n","Epoch 00005: val_acc improved from 0.89076 to 0.89286, saving model to vgg16_best.h5\n","Epoch 6/20\n","3808/3808 [==============================] - 30s 8ms/step - loss: 0.1474 - acc: 0.9485 - val_loss: 0.3263 - val_acc: 0.8887\n","\n","Epoch 00006: val_acc did not improve from 0.89286\n","Epoch 7/20\n","3808/3808 [==============================] - 30s 8ms/step - loss: 0.1169 - acc: 0.9572 - val_loss: 0.3052 - val_acc: 0.9002\n","\n","Epoch 00007: val_acc improved from 0.89286 to 0.90021, saving model to vgg16_best.h5\n","Epoch 8/20\n","3808/3808 [==============================] - 30s 8ms/step - loss: 0.0983 - acc: 0.9674 - val_loss: 0.3356 - val_acc: 0.8792\n","\n","Epoch 00008: val_acc did not improve from 0.90021\n","Epoch 9/20\n","3808/3808 [==============================] - 30s 8ms/step - loss: 0.1057 - acc: 0.9653 - val_loss: 0.3105 - val_acc: 0.9013\n","\n","Epoch 00009: val_acc improved from 0.90021 to 0.90126, saving model to vgg16_best.h5\n","Epoch 10/20\n","3808/3808 [==============================] - 30s 8ms/step - loss: 0.0954 - acc: 0.9690 - val_loss: 0.3379 - val_acc: 0.8971\n","\n","Epoch 00010: val_acc did not improve from 0.90126\n","Epoch 11/20\n","3808/3808 [==============================] - 30s 8ms/step - loss: 0.0898 - acc: 0.9695 - val_loss: 0.3482 - val_acc: 0.8782\n","\n","Epoch 00011: val_acc did not improve from 0.90126\n","Epoch 12/20\n","3808/3808 [==============================] - 30s 8ms/step - loss: 0.0862 - acc: 0.9724 - val_loss: 0.3099 - val_acc: 0.8939\n","\n","Epoch 00012: val_acc did not improve from 0.90126\n","Epoch 13/20\n","3808/3808 [==============================] - 30s 8ms/step - loss: 0.0772 - acc: 0.9732 - val_loss: 0.3009 - val_acc: 0.9013\n","\n","Epoch 00013: val_acc did not improve from 0.90126\n","Epoch 14/20\n","3808/3808 [==============================] - 30s 8ms/step - loss: 0.0776 - acc: 0.9730 - val_loss: 0.3294 - val_acc: 0.8908\n","\n","Epoch 00014: val_acc did not improve from 0.90126\n","Epoch 00014: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f9ad484d128>"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"QbdMIERR_JI4","colab_type":"code","colab":{}},"source":["# Accuraices much better than my model, (with trained weights and architecture from the ImageNet challenge), proving the usefullness of transfer learning."],"execution_count":0,"outputs":[]}]}